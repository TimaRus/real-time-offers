version: '3.7'

networks:
  kafka-net:
    driver: bridge

services:
  # Kafka Cluster
  kafka-cluster:
    image: landoop/fast-data-dev:2.3.2
    container_name: kafka-cluster
    environment:
      ADV_HOST: kafka-cluster     # Указываем hostname контейнера
      RUNTESTS: 0                 # Disable the (coyote) integration tests from running when container starts
      SAMPLEDATA: 0               # Do not create topics with sample avro and json records
      FORWARDLOGS: 0              # Disable running the file source connector that brings broker logs into a Kafka topic
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-cluster:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
    ports:
      - 2181:2181                 # Zookeeper
      - 3030:3030                 # Landoop UI
      - 8081-8083:8081-8083       # REST Proxy, Schema Registry, Kafka Connect ports
      - 9581-9585:9581-9585       # JMX Ports
      - 9092:9092                 # Kafka Broker
    networks:
      - kafka-net
    volumes:
      - ./docker_data/landoop_data:/data
      - ./datasets:/datasets

  # Custom initialization container
  init-container:
    container_name: init-container
    image: landoop/fast-data-dev:2.3.2
    entrypoint: /bin/bash -c "sleep 30 && /scripts/setup.sh && tail -f /dev/null"  # Запуск скрипта для инициализации и команда, чтобы контейнер остался "живым"
    volumes:
      - ./scripts:/scripts
    depends_on:
      - kafka-cluster
    networks:
      - kafka-net

  # Spark master
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - JUPYTER_RUNTIME_DIR=/opt/bitnami/jupyter_data
      - JUPYTER_NOTEBOOK_DIR=/opt/bitnami/jupyter_data
    ports:
      - "7077:7077"  # Spark Master
      - "8080:8080"  # Spark Master UI
      - "8888:8888"  # Jupyter Notebook
    #command: /bin/bash -c "start-master.sh && jupyter-notebook --allow-root --ip=0.0.0.0 --port=8888 --no-browser --NotebookApp.notebook_dir='/home/jovyan/work'"
    # To start Jupyter Notebook: jupyter-notebook --allow-root --ip=0.0.0.0 --port=8888 --no-browser --NotebookApp.notebook_dir='/home/jovyan/work'
    volumes:
      - ./docker_data/jupyter_notebooks:/home/jovyan/work
      - ./docker_data/jupyter_data:/opt/bitnami/jupyter_data
      - ./streaming_pipeline.py:/opt/bitnami/spark/streaming_pipeline.py
    networks:
      - kafka-net

  # Spark worker
  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    ports:
      - "8079:8081"  # Spark Worker UI
    volumes:
      - ./docker_data/jupyter_notebooks:/home/jovyan/work
      - ./docker_data/jupyter_data:/opt/bitnami/jupyter_data
    networks:
      - kafka-net
    depends_on:
      - spark-master

  # Redis
  redis:
    image: redis:7.0-alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - kafka-net
    volumes:
      - ./docker_data/redis:/data
    command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]  # Запуск Redis

  # ClickHouse
  clickhouse:
    image: clickhouse/clickhouse-server:23.9-alpine
    container_name: clickhouse
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native TCP interface
    networks:
      - kafka-net
    volumes:
      - ./docker_data/clickhouse:/var/lib/clickhouse